4.
퍼셉트론(Perceptron) - AI의 뉴런 구조.

신공신경망

딥러닝 : 
히든레이어가 퍼셉트론을 연결해서 가중치를 세팅해놓는것.
강아지사진을 히든레이어에서 체크해서 마지막 판별하는것.
히든레이어가 중요해보인다.
5.
input layer ->hidden layer ->output layer

6.
학습은 트레이닝
학습이 된것은 pre-trained model. 뭐. 

7. 인공지능은 두개로 구분된다.
 (1) 학습(Train)
	GPU가 꼭 필요하다.
 (2) 추론(Inference) = Pre-Trained Model
	GPU가 꼭 필요하진 않다.

8. 생성형 AI
 Zero-Shot
 One-Shot
 Few-Shot
 ~ 개의 데이터를 주고 만든다. 최근에는 제로샷이다.

인공지능 - 인간의 지적능력을 컴퓨터로 구현
머신러닝 - 스스로 학습.
딥러닝 - 인간의 뉴런과 비슷한 인공신경망으로 학습.

10
머신러닝은 사람이 관여해야한다. 사람이 맞는지 판단해야한다.
딥러닝은 사람의 관여가 없다. 미리 문제와 답을 줘야한다.
존나 많이.
문제와 답을 딥러닝 학습할때 제공
=> 데이터셋(Dataset)


머신러닝의 학습방법
지도 학습 : 문제와 답을 알려주고 학습. - 예측, 분류밖에 못한다. 다만 그 범위가 넓다.
비지도 학습 : 답을 가르쳐주지않고 학습. - 군집 
강화 학습 : 보상을 준다. 자율주행 등. - 
Another level - 생성형 인공지능

11. 생성형 AI의 비용을 줄이기 위하여 나온 대안
=>오픈소스(OpenSource)
12. Nvidia Digits
 AI-Agents
 채팅
 로컬 LLM을 구축하는것 = sLLM (small Large Language Model)

13. GPU의 핵심
     하드웨어
     소프트 웨어
     =>CUDA, CuDNN

14. TensorFlow로 강화 학습.
 내부에 Q-Learning이라는 프로그램이 포함되어있다. 흔히 아는 그 딥러닝 그거.
 따로 공부해야돼.

지도 학습 - 라벨링

생성형 인공지능은 법리적인 문제가 있다.
 ex - 보험

epoch - 반복회수?
훈련셋은 많은 데이터를 반복하고, 시험셋은 작은 데이터로 한번실행.
이 과정이 Train.

15. 학습 진행 결과
	훈련 평가  실제 적용
	98%  95%       93%
A	98%  97%       63% - > 훈련 데이터와 실제 데이터가 다르다.
B	96%  71%       70% - > 인공지능 알고리즘 오류

활성화 함수 : 적절한 것을 적절하게 써야한다.
 - 시그모이드(sigmoid) 함수
   : 분류에 쓴다. 넓은 범위를 0과 1 사이에 정규화시킨다.
 - ReLu(Rectified(정류) Linear Unit)
   : 음수는 0으로, 양수는 뭐 비례하는 함수.

16. 인공지능
활성화함수의 역할
x축이 문제고, y는 답
문제, 답 = 공식
처음보는 문제도 공식에 의해서 유사한 답을 얻을 수 있다.
추론을 통해서,
문제에 공식(답)을 이용하여 유사한 답을 제공한다.


17. 활성화 함수
손실함수 : 가중치의 오차를 줄인다.  0에 가까울수록 성능이 좋다.
loss function : 
	Mean Squared Error : MSE
		Regression 문제에 자주 활용.
		학습이 한번 끝나고 나서, 가중치 값을 조정해주기위해서 사용하는 방식이며, 회귀문제에 사용
	CEE Cross Entropy Error : CEE
		Classification 문제에서 자주 활용.


18. 원-핫 인코딩
데이터값
1 [0,0,0,0,0,1] 10
2 [0,0,0,0,1,0] 20
3 [0,0,0,1,0,0] 30
4 [0,0,1,0,0,0] 40
..

Q? 뭔지 모르겠다.

19. 경사 하강법 Gradient descent
안정값을 찾는, 기울기에 반대방향으로 진행하는 함수.
극소값을 피해서 최소값을 찾기위한 방법 -> Optimizer

인공지능의 성능은 데이터를 얼마나 잘 가공해서 잘 설계했냐가 중요하다. 전처리가 중요하다.
신경망 만들기. 실습할거야
모델 만들고, 학습시키기.
적용하기, 예측.

다시말하면, 학습과 추론 두가지로 나누어진다.

--
딥러닝 결과분석. 

--

인공지능 신경망 7가지
ANN - 의료.
CNN (이미지/측정 분석용)
RNN/LSTM (잡음 예측, 시계열 분석)
강화학습용 신경망 (제어 최적화)
Autoencoder (에러 검출 및 상태 추정)
(WebUI - 웹으로 실행된다.)

Convolution Neural Network : 합성곱 신경망
시각으로 가장 많이쓴다. 대체불가하다.
Input - convolution + ReLU - Pooling - Convolution 
Channel
Pooling : 줄이는 것.
Max Pooling : 특정 구역에서 맥스값만 추출. 
Average ''
Min '' 
셋다 스케일만 다르지 결국 비슷하다.
-----------------
